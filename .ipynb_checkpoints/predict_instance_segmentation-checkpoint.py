# -*- coding: utf-8 -*-
"""Predict_Instance Segmentation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Dj8v3JBk1mNC0XF8Do2BMPaxVgbbUZS

# **Predict**
"""

!pip3 install -r requirements.txt

!python3 setup.py install

import mrcnn
import mrcnn.config
import mrcnn.model
import mrcnn.visualize
import cv2
import os
import glob
import itertools
from tqdm import tqdm

!pip3 install -r requirements.txt
!python3 setup.py install

# load the class label names from disk, one label per line
CLASS_NAMES = open("labels.txt").read().strip().split("\n")

#This cell defines InferenceConfig and loads the best trained model.
class InferenceConfig(FashionConfig):
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
inference_config = InferenceConfig()

glob_list = glob.glob(f'/content/drive/MyDrive/my_model.h5')
model_path = glob_list[0] if glob_list else ''

#Creating a model for inference
model = modellib.MaskRCNN(mode='inference',#'inference' mode for predictions
                          config=inference_config,
                          model_dir=ROOT_DIR)

assert model_path != '/drive/My Drive/my_model.h5'
model.load_weights(model_path, by_name=True)

def resize_image(image_path):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA)
    return img

image = resize_image(image_path)
r = model.detect([image], verbose=0)
r=r[0]

"""# **Additional functions:**

# 1.   **Convert data to run-length encoding**
"""

"""
The to_rle(bits) function converts a two-dimensional array of bits into a compressed format based on Run-Length Encoding (RLE).
This format is used to represent binary images or masks where the same value (0 or 1) is repeated consecutively.
pos: The starting position for this group (where sequence 1 starts).
sum(group_list): The number of times the value 1 occurs in this group.
The function returns a rle list that contains the position pairs and the number of repetitions for all groups of the value 1."""


def to_rle(bits):
    rle = []
    pos = 0         #position (index) in the bit array, initially set to 0.
    """grouping of adjacent values ​​in bits. For example, if bits has the value [0, 0, 1, 1, 1, 0],
       then there will be two groups: one of 0 and one of 1."""
    for bit, group in itertools.groupby(bits):
        group_list = list(group)
        if bit:
            rle.extend([pos, sum(group_list)])
        pos += len(group_list)
    return rle

"""# 2.   **A function to optimize mask quality by removing overlaps and ensuring tight bounding boxes.**

*** The trim_masks function is designed to refine the masks and bounding boxes generated by a Mask R-CNN model.
It addresses potential issues where multiple masks might overlap or be redundant,
ensuring that each object is represented by a single, well-defined mask.
This is important for improving the training of segmentation models, after which it eliminates some conflicts in the data. ***


---

\

1.   **Sorting classes and creating RLE:**

\
Classes are sorted in ascending order, and then converted to a Run-Length Encoding (RLE) representation for more efficient processing of groups of identical classes.

**- Iterating over groups of classes:**
The function iterates over groups of objects with the same class.

**- Combining masks within a group:**
For each group, a combined mask is created, initially set to zero.
Then, each mask in the group is combined with the combined mask using a logical "AND" operation to remove overlaps.

**- Trimming masks:**
After combining the masks, each mask is trimmed to the minimum bounding box that encompasses all non-zero pixels.

**- Updating bounding boxes:**
The bounding boxes for each mask are updated according to the new coordinates obtained after trimming.

\

2.   **When to apply:**

\

This function is typically applied after the Mask R-CNN model has detected objects and generated initial masks. It is useful in scenarios where:

**- Masks overlap:**
The function removes redundant masks and ensures that each object is represented by a single mask.

**- Mask boundaries are inaccurate:**
The function can improve the accuracy of mask boundaries by trimming them to the minimum bounding box.

**- Improving object detection accuracy:**
Removing overlapping masks can improve the accuracy of object detection and segmentation.

\

3.   **Summary:**

\
The trim_masks function is a valuable tool for improving the results of the Mask R-CNN model. It helps to obtain more accurate and clear masks for each detected object.


---


**This function "cleans up" the masks generated by the model. It ensures that each object is highlighted with a single, clear mask without any extra pieces.**
"""

def trim_masks(masks, rois, class_ids):
    class_pos = np.argsort(class_ids)
    class_rle = to_rle(np.sort(class_ids))

    pos = 0
    for i, _ in enumerate(class_rle[::2]):
        previous_pos = pos
        pos += class_rle[2*i+1]
        if pos-previous_pos == 1:
            continue
        mask_indices = class_pos[previous_pos:pos]

        union_mask = np.zeros(masks.shape[:-1], dtype=bool)
        for m in mask_indices:
            masks[:, :, m] = np.logical_and(masks[:, :, m], np.logical_not(union_mask))
            union_mask = np.logical_or(masks[:, :, m], union_mask)
        for m in mask_indices:
            mask_pos = np.where(masks[:, :, m]==True)
            if np.any(mask_pos):
                y1, x1 = np.min(mask_pos, axis=1)
                y2, x2 = np.max(mask_pos, axis=1)
                rois[m, :] = [y1, x1, y2, x2]

    return masks, rois

"""

---


**If the initial masks generated by the model are already sufficiently accurate and do not have significant overlaps, then the application of the function may be optional. Applying the trim_masks function is a recommended step when working with Mask R-CNN models, as it helps to obtain better and more accurate results.**"""