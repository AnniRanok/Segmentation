# -*- coding: utf-8 -*-
"""Predict_Instance Segmentation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Dj8v3JBk1mNC0XF8Do2BMPaxVgbbUZS

# **Predict**
"""

!pip3 install -r requirements.txt

!python3 setup.py install

import mrcnn
import mrcnn.config
import mrcnn.model
import mrcnn.visualize
import cv2
import os
import glob
import itertools
from tqdm import tqdm


# load the class label names from disk, one label per line
#CLASS_NAMES = open("labels.txt").read().strip().split("\n")
CLASS_NAMES = [
    'T-shirt',
    'Long-Sleeve T-Shirt',
    'Tank Top',
    'Crop Top',
    'Off-Shoulder Top',
    'Halter Top',
    'Top',
    'Blouse',
    'Shirt',
    'Shirt Short-Sleeve',
    'Sweater',
    'Cardigan',
    'Vest',
    'Puffer Vest',
    'Denim Vest',
    'Hoodie',
    'Sweatshirt',
    'Tunic',
    'Kimono',
    'Polo',
    'Jersey',
    'Denim Jacket',
    'Leather Jacket',
    'Bomber Jacket',
    'Puffer Jacket',
    'Quilted Jacket',
    'Windbreaker',
    'Varsity Jacket',
    'Blouson Jacket',
    'Short Blazer',
    'Long Blazer',
    'Fitted Blazer',
    'Oversized Blazer',
    'Coat',
    'Trench Coat',
    'Peacoat',
    'Overcoat',
    'Duffle Coat',
    'Parka',
    'Wool Coat',
    'Down Coat',
    'Raincoat',
    'Cape',
    'Gilet',
    'Pants',
    'Pants Capri',
    'Leggings',
    'Jeans',
    'Shorts',
    'Mini Skirt',
    'Midi Skirt',
    'Maxi Skirt',
    'Mini Dress',
    'Midi Dress',
    'Maxi Dress',
    'Jumpsuit',
    'Gown',
    'Sandals',
    'Flip Flops',
    'Espadrilles',
    'Sneakers',
    'Boots',
    'Loafers',
    'Oxfords',
    'Ballet Flats',
    'Mules',
    'Heels',
    'Bag',
    'Backpack',
    'Necklace',
    'Glasses',
    'Bangles',
    'Shawl'
]

#This cell defines InferenceConfig and loads the best trained model.
class InferenceConfig(FashionConfig):
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
inference_config = InferenceConfig()

glob_list = glob.glob(f'/content/drive/MyDrive/my_model.h5')
model_path = glob_list[0] if glob_list else ''

#Creating a model for inference
model = modellib.MaskRCNN(mode='inference',#'inference' mode for predictions
                          config=inference_config,
                          model_dir=ROOT_DIR)

# Load the weights into the model.
assert model_path != '/drive/My Drive/my_model.h5'
model.load_weights(model_path, by_name=True)


# Load the input image, convert it from BGR to RGB channel
def resize_image(image_path):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA)
    return img


# Get the results for the first image.
image = resize_image(image_path)
r = model.detect([image], verbose=0)
r=r[0]

# Visualize the detected objects.
mrcnn.visualize.display_instances(image=image, 
                                  boxes=r['rois'], 
                                  masks=r['masks'], 
                                  class_ids=r['class_ids'], 
                                  class_names=CLASS_NAMES, 
                                  scores=r['scores'])



"""
If it occurs need to pass only mask outlines to the frontend and not the masks themselves, then masks can easily be converted to outlines using image processing techniques. One approach is to use an OpenCV library that allows you to extract contours from binary masks.
 """

from google.colab.patches import cv2_imshow
"""
Binary mask 8-bit. The mask returned by Mask R-CNN represents objects as pixels with two values ​​- 0 and 1 (0 for the background and 1 for the object). We convert these values ​​to 8-bit format, where 0 corresponds to black and 255 to white (the object).
"""

binary_mask_8bit = (binary_mask * 255).astype(np.uint8)

""" 
We find the contours of the mask. The findContours function identifies the boundaries between the object and the background, returning a list of points describing these boundaries (contours).
"""

contours, hierarchy = cv2.findContours(binary_mask_8bit, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
"""
RETR_EXTERNAL: This option means that we only want to find the outer contours of objects. Other options can also find internal contours.
CHAIN_APPROX_SIMPLE: This option simplifies the contours by keeping only the key points that describe the shape of the object.
"""

# Convert a mask to an image for rendering contours
contour_image = cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2BGR)

# We draw contours on the image
cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)
# We display images with contours
cv2_imshow(contour_image)





"""# **Additional functions:**

# 1.   **Convert data to run-length encoding**
"""

"""
The to_rle(bits) function converts a two-dimensional array of bits into a compressed format based on Run-Length Encoding (RLE).
This format is used to represent binary images or masks where the same value (0 or 1) is repeated consecutively.
pos: The starting position for this group (where sequence 1 starts).
sum(group_list): The number of times the value 1 occurs in this group.
The function returns a rle list that contains the position pairs and the number of repetitions for all groups of the value 1."""


def to_rle(bits):
    rle = []
    pos = 0         #position (index) in the bit array, initially set to 0.
    """grouping of adjacent values ​​in bits. For example, if bits has the value [0, 0, 1, 1, 1, 0],
       then there will be two groups: one of 0 and one of 1."""
    for bit, group in itertools.groupby(bits):
        group_list = list(group)
        if bit:
            rle.extend([pos, sum(group_list)])
        pos += len(group_list)
    return rle

"""# 2.   **A function to optimize mask quality by removing overlaps and ensuring tight bounding boxes.**

*** The trim_masks function is designed to refine the masks and bounding boxes generated by a Mask R-CNN model.
It addresses potential issues where multiple masks might overlap or be redundant,
ensuring that each object is represented by a single, well-defined mask.
This is important for improving the training of segmentation models, after which it eliminates some conflicts in the data. ***


---

\

1.   **Sorting classes and creating RLE:**

\
Classes are sorted in ascending order, and then converted to a Run-Length Encoding (RLE) representation for more efficient processing of groups of identical classes.

**- Iterating over groups of classes:**
The function iterates over groups of objects with the same class.

**- Combining masks within a group:**
For each group, a combined mask is created, initially set to zero.
Then, each mask in the group is combined with the combined mask using a logical "AND" operation to remove overlaps.

**- Trimming masks:**
After combining the masks, each mask is trimmed to the minimum bounding box that encompasses all non-zero pixels.

**- Updating bounding boxes:**
The bounding boxes for each mask are updated according to the new coordinates obtained after trimming.

\

2.   **When to apply:**

\

This function is typically applied after the Mask R-CNN model has detected objects and generated initial masks. It is useful in scenarios where:

**- Masks overlap:**
The function removes redundant masks and ensures that each object is represented by a single mask.

**- Mask boundaries are inaccurate:**
The function can improve the accuracy of mask boundaries by trimming them to the minimum bounding box.

**- Improving object detection accuracy:**
Removing overlapping masks can improve the accuracy of object detection and segmentation.

\

3.   **Summary:**

\
The trim_masks function is a valuable tool for improving the results of the Mask R-CNN model. It helps to obtain more accurate and clear masks for each detected object.


---


**This function "cleans up" the masks generated by the model. It ensures that each object is highlighted with a single, clear mask without any extra pieces.**
"""

def trim_masks(masks, rois, class_ids):
    class_pos = np.argsort(class_ids)
    class_rle = to_rle(np.sort(class_ids))

    pos = 0
    for i, _ in enumerate(class_rle[::2]):
        previous_pos = pos
        pos += class_rle[2*i+1]
        if pos-previous_pos == 1:
            continue
        mask_indices = class_pos[previous_pos:pos]

        union_mask = np.zeros(masks.shape[:-1], dtype=bool)
        for m in mask_indices:
            masks[:, :, m] = np.logical_and(masks[:, :, m], np.logical_not(union_mask))
            union_mask = np.logical_or(masks[:, :, m], union_mask)
        for m in mask_indices:
            mask_pos = np.where(masks[:, :, m]==True)
            if np.any(mask_pos):
                y1, x1 = np.min(mask_pos, axis=1)
                y2, x2 = np.max(mask_pos, axis=1)
                rois[m, :] = [y1, x1, y2, x2]

    return masks, rois

"""

---


**If the initial masks generated by the model are already sufficiently accurate and do not have significant overlaps, then the application of the function may be optional. Applying the trim_masks function is a recommended step when working with Mask R-CNN models, as it helps to obtain better and more accurate results.**"""